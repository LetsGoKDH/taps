# 3.1 라벨링 자동화 워크플로우 조사 및 베이스라인 결정 (TAPS Train/Dev)

## 1. 목적과 전제

### 목적
TAPS 데이터셋의 **Train/Dev split에서 비어 있는 `text`를 자동으로 생성**하고, 이를 기반으로 **`normalized text`를 일관되게 생성**하기 위한 라벨링 자동화 워크플로우를 조사·비교한 뒤, 프로젝트의 **베이스라인 워크플로우**를 확정한다.

### 전제(Assumptions)
- Train/Dev의 `text`는 비어 있으며, 프로젝트에서 이를 생성해야 한다.
- Throat/Acoustic은 **동일 발화(동일 문장)를 두 채널로 녹음한 페어**이며, **최종 텍스트 라벨은 채널 간 공유**한다.
- 본 단계(3.1)에서는 “데이터 증강/보강”은 범위 밖이며, **일반적인 음성→텍스트 라벨링**에 집중한다.
- 실행 환경은 **로컬 노트북 또는 Google Colab**에서 무리 없이 구동 가능해야 한다.

---

## 2. 후보 워크플로우 분류

본 조사에서는 음성-텍스트 라벨링 자동화 접근을 다음 3가지 계열로 분류했다.

### A) 딥러닝 기반 자동 전사(ASR) 중심
- 예: Whisper 계열, Wav2Vec2 계열, 기타 오픈소스 ASR
- 음성 입력 → 텍스트 출력(문장 단위 전사 생성)

### B) 규칙 기반/강제정렬(Forced Alignment) 중심
- 예: Montreal Forced Aligner(MFA) 등
- **텍스트가 이미 존재**할 때: 음성-텍스트를 시간축으로 정렬/검증(텍스트 “생성”이 아니라 “정렬”)

### C) 하이브리드(ASR + 트리아지 + 최소 수동검수 + 규칙 정규화)
- ASR로 초안 생성 후, 자동 점수화로 검수 대상만 선별하고, 규칙 기반 정규화를 통해 재현성을 확보

---

## 3. 워크플로우 비교(장단점 및 적합성)

| 워크플로우 | 개요 | 장점 | 단점/리스크 | TAPS(Train/Dev text 비어 있음) 적합성 |
|---|---|---|---|---|
| A) ASR 단독(완전 자동) | Acoustic(또는 둘 다)에 ASR 실행 → 결과를 정답으로 고정 | 구현 단순, 빠른 처리, Colab 친화적 | 오인식이 그대로 “정답 라벨”로 고정될 위험. 품질 관리 부재 | **중간** (빠르지만 품질 담보 어려움) |
| B) Forced Alignment 단독 | 텍스트가 있을 때만 음성에 정렬(시간정보/검증) | 텍스트가 정확하면 정렬 품질 높음, 시간 라벨 생성 용이 | **텍스트가 없으면 시작 불가**. 현재 과제(텍스트 생성)와 불일치 | **낮음** (현 단계 핵심 문제 해결 불가) |
| C) 하이브리드(추천) | **Acoustic-only ASR → 자동 트리아지 → 필요한 샘플만 검수 → 규칙 정규화** | 품질/효율 균형. “정답 라벨”로서의 신뢰성 확보. 정규화는 결정적(deterministic)으로 재현성 확보 | 구성요소가 늘어 구현이 약간 복잡. 트리아지 기준 설계 필요 | **높음** (텍스트 생성 문제를 직접 해결 + 품질 관리 가능) |

**핵심 결론:**  
Train/Dev의 `text`가 비어 있는 상황에서는 **텍스트 생성이 선결 과제**이므로, 정렬 도구(Forced Alignment)는 3.1의 베이스라인으로 부적합하다. 따라서 **ASR 기반 생성**이 필수이며, “정답 라벨 고정”을 위해서는 **품질 트리아지 + 최소 검수 + 결정적 정규화**를 포함하는 하이브리드가 최적이다.

---

## 4. 베이스라인 워크플로우 결정(3.1 최종안)

### 4.1 정책(Policy): 텍스트 라벨의 단위
- 최종 텍스트 라벨은 **sample_id(문장) 단위로 1개만 존재**한다.
- Throat/Acoustic은 동일 발화이므로 동일 텍스트를 **공유**한다.
- 따라서 텍스트 생성은 **Acoustic 기준**으로 수행한다(품질/일반성 측면에서 유리).

### 4.2 산출물(Artifacts): 텍스트 3종 분리
아래 3개 필드를 **명확히 분리하여 관리**한다.

1) `text_raw`: ASR이 출력한 원문(자동 생성 결과, 변경 최소화)  
2) `text_verified`: “정답 라벨”로 확정한 전사 텍스트(필요 시 최소 수정 반영)  
3) `text_normalized`: 학습/평가에 사용할 정규화 텍스트(규칙 기반, 재현성 확보)

> 원칙: `text_raw`는 최대한 보존하고, 사람이 고치는 것은 `text_verified`에서만 수행한다. `text_normalized`는 항상 `text_verified → normalize()`로 생성한다.

### 4.3 파이프라인(Workflow)
**Step 0. 입력 단위 확정**  
- 입력은 “샘플 ID(문장)”이며, Acoustic 오디오 경로를 기준으로 처리한다.

**Step 1. Acoustic-only ASR 실행 → `text_raw` 생성**  
- Colab/로컬에서 재현 가능한 ASR 엔진 1개를 베이스로 고정한다.
- 실행 파라미터(모델 크기, 디코딩 옵션 등)는 문서/코드로 고정한다.

**Step 2. 자동 품질 트리아지(Triage)**
- 모든 샘플에 대해 간단한 proxy 지표로 신뢰도를 점수화하고, A/B/C로 버킷팅한다.
  - A(High): 자동 확정 후보
  - B(Medium): 빠른 검수 대상
  - C(Low): 집중 검수/보류 대상

> 목적: 전체를 수동 검수하지 않으면서도 “정답 라벨로서의 품질”을 확보한다.

**Step 3. (필요 샘플만) 최소 수동 검수 → `text_verified` 확정**
- 기본 정책: A는 `text_verified = text_raw`로 두고, B/C 위주로만 듣고 수정한다.
- 검수 결과는 “수정 로그/근거”를 남겨 재현 가능하게 한다.

**Step 4. 규칙 기반 정규화 → `text_normalized` 생성**
- 정규화는 반드시 결정적(deterministic) 규칙/모듈로 수행한다.
- 숫자/단위/기호/공백/한글화 등 한국어 도메인 규칙은 3.2에서 정리하고 3.3~에서 확장한다.

---

## 5. 트리아지 설계(초기 권장안)

ASR 모델이 “정확도 점수”를 일관되게 제공하지 않는 경우가 많아, 초기에는 아래와 같은 **proxy 지표 기반**으로 충분하다.

- (가능하면) 평균 logprob, no_speech_prob, 디코딩 fallback 여부
- 오디오 길이 대비 토큰 수(비정상적으로 길거나 짧은 경우 플래그)
- 반복 토큰/반복 구문 탐지(모델 붕괴 패턴)
- VAD 기반 “실제 발화 구간”이 너무 짧거나 긴 경우 플래그

초기 운영 전략:
- **보수적으로 B/C를 넉넉히 잡고**, 검수량을 관측하면서 점진적으로 기준을 조정한다.

---

## 6. 리스크 및 완화책

### 리스크 1) ASR 오인식이 정답 라벨로 고정되는 문제
- **완화:** 트리아지 + 선택적 검수(특히 C 버킷은 반드시 확인)
- `text_raw`와 `text_verified` 분리로, 무엇이 자동 생성이고 무엇이 사람이 확정했는지 명확히 한다.

### 리스크 2) 정규화가 의미를 바꾸는 문제(비가역 변환)
- **완화:** 정규화는 `text_verified → text_normalized`의 단방향 파이프라인으로 고정하고, 항상 원문(`text_verified`)을 보존한다.
- 정규화 규칙은 테스트 케이스 기반으로 확장(3.5~3.6 검증 단계).

### 리스크 3) 파인튜닝 여부 결정의 혼선
- **완화:** 3.1 단계에서는 파인튜닝을 “결정”하지 않는다.  
  트리아지 결과(B/C 비율, 오류 패턴)를 근거로, 필요할 때 3.x 후반부에서 옵션으로 검토한다.

---

## 7. 3.1 단계 산출물(Deliverables)

3.1 완료 기준은 아래 3가지를 레포에 남기는 것이다.

1) **워크플로우 결정 문서(본 문서)**
2) **라벨 스키마 정의**
   - sample_id 기준: `text_raw`, `text_verified`, `text_normalized`, `triage_bucket`, `triage_score`, `notes`
3) **최소 파이프라인 실행 계획**
   - ASR 엔진/버전/파라미터 고정
   - 트리아지 기준 초안
   - 검수 운영 방식(버킷 B/C 중심)

---

## 8. 다음 단계(3.2로의 연결)

- 3.2에서는 한국어 라벨링/정규화에서 빈번히 발생하는 도메인 이슈(숫자, 단위, 띄어쓰기, 고유명사, 영어/약어 혼용 등)를 정리하고,
- 3.3~3.6에서 정규화 모듈을 강화하고, 가능한 엣지케이스까지 자동 검증 체계를 확장한다.

---

## 부록: 왜 Forced Alignment를 3.1 베이스에서 제외했는가
Forced Alignment는 “텍스트가 존재할 때” 음성-텍스트를 시간축에 정렬하는 데 강력하지만, 3.1의 핵심 과제는 Train/Dev의 **텍스트 자체를 생성**하는 것이므로, 정렬 도구는 **후속 단계(예: 단어 단위 타임스탬프가 필요할 때)**에 선택적으로 도입하는 것이 합리적이다.
