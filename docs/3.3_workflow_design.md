# 3.3 라벨링 자동화 워크플로우 설계

## 1. 목적

3.1에서 결정한 하이브리드 워크플로우(ASR → 트리아지 → 검수 → 정규화)를 구체적인 폴더 구조와 코드 모듈로 설계한다.

---

## 2. 폴더 구조

```
data/
├── taps_dataset/              # TAPS 원본 데이터셋 (로컬 저장)
│   ├── train/
│   ├── dev/
│   └── test/
├── outputs/                   # 처리 결과물
│   ├── raw/                   # Step 1: ASR 원본 출력 (text_raw)
│   ├── verified/              # Step 3: 검수 완료 (text_verified)
│   └── normalized/            # Step 4: 정규화 완료 (text_normalized)
└── triage/                    # Step 2: 트리아지 결과
    ├── bucket_a/              # A등급: 자동 확정 후보
    ├── bucket_b/              # B등급: 빠른 검수 대상
    └── bucket_c/              # C등급: 집중 검수 대상
```

**주요 원칙:**
- `data/` 폴더는 `.gitignore`에 포함 (GitHub에 업로드하지 않음)
- 데이터셋은 한 번만 다운로드하고 로컬에 저장
- 각 단계의 결과물은 별도 폴더에 분리 저장

---

## 3. 코드 모듈 구조

```
src/taps/
├── __init__.py
├── normalizer.py              # 정규화 엔진 (기존, v0.6.4)
└── data/                      # 데이터 관리 모듈 (신규)
    ├── __init__.py
    └── loader.py              # 데이터셋 다운로드/로드
```

### 3.1 데이터 로더 (`src/taps/data/loader.py`)

| 함수 | 설명 |
|------|------|
| `download_and_save()` | HuggingFace에서 다운로드 → 로컬 저장 |
| `load_local()` | 로컬에서 데이터셋 로드 (빠름) |
| `get_split(split)` | 특정 split만 로드 (train/dev/test) |
| `is_dataset_downloaded()` | 다운로드 여부 확인 |

**사용 예시:**

```python
from taps.data import download_and_save, load_local

# 처음 한 번만 실행 (인터넷 필요)
download_and_save()

# 이후부터는 로컬에서 로드 (인터넷 불필요, 빠름)
ds = load_local()
train = ds["train"]
dev = ds["dev"]
```

---

## 4. 워크플로우 파이프라인 (3.4에서 구현 예정)

```
┌─────────────────────────────────────────────────────────────────┐
│                     TAPS 라벨링 자동화 파이프라인                   │
└─────────────────────────────────────────────────────────────────┘

Step 0. 데이터 로드
    │
    │  load_local() → data/taps_dataset/
    │
    ▼
Step 1. ASR 실행 (Whisper Large-v3)
    │
    │  Acoustic 오디오 → text_raw
    │  저장: data/outputs/raw/
    │
    ▼
Step 2. 자동 트리아지
    │
    │  신뢰도 점수 계산 → A/B/C 버킷팅
    │  저장: data/triage/bucket_{a,b,c}/
    │
    ▼
Step 3. 선택적 검수
    │
    │  A: 자동 확정 (text_verified = text_raw)
    │  B/C: 사람이 듣고 수정
    │  저장: data/outputs/verified/
    │
    ▼
Step 4. 규칙 기반 정규화 (Kornormalizer)
    │
    │  text_verified → text_normalized
    │  저장: data/outputs/normalized/
    │
    ▼
완료: 최종 라벨 데이터셋
```

---

## 5. 선정된 도구

| 용도 | 도구 | 버전/설정 |
|------|------|----------|
| ASR 모델 | Whisper Large-v3 | `Systran/faster-whisper-large-v3` |
| ASR 설정 | beam_size=5, language="ko" | temperature=[0.0, 0.2, 0.4] |
| 정규화 | Kornormalizer | NumberToKorean, AlphabetToKorean |
| 데이터셋 | HuggingFace datasets | `save_to_disk` / `load_from_disk` |

---

## 6. 트리아지 시스템 설계

### 6.1 목적

ASR 출력 결과의 신뢰도를 자동으로 평가하여 A/B/C 버킷으로 분류한다.
- **A (High)**: 자동 확정 → `text_verified = text_raw`
- **B (Medium)**: 빠른 검수 대상
- **C (Low)**: 집중 검수/보류 대상

### 6.2 평가 지표

| 지표 | 출처 | 용도 | 설명 |
|------|------|------|------|
| `avg_logprob` | Whisper 제공 | 전체 신뢰도 | 모델이 출력을 얼마나 확신하는지 (-1~0, 0에 가까울수록 확신) |
| `compression_ratio` | Whisper 제공 | 모델 붕괴 탐지 | 출력 텍스트의 반복성 (정상: 1.0~2.5, 붕괴: 4.0+) |
| 반복 n-gram | 직접 계산 | 텍스트 붕괴 탐지 | 같은 토큰/구문이 연속 반복되는 패턴 |
| 최소 길이 | 직접 계산 | 빈 출력 탐지 | 출력 텍스트가 비정상적으로 짧은 경우 |

**제외한 지표:**
- `no_speech_prob`: TAPS는 실험실 녹음 데이터로 무음 구간이 거의 없음
- 오디오 길이 대비 토큰 수: 깨끗한 데이터에서는 큰 의미 없음
- 사전 기반 체크: 정규화 전이라 오탐률이 높음 (숫자, 영문, 고유명사)

### 6.3 분류 규칙 (Rule-based)

```python
def triage(text, avg_logprob, compression_ratio):
    """
    ASR 결과를 A/B/C 버킷으로 분류

    Returns:
        bucket: "A", "B", or "C"
        reason: 분류 사유
    """
    # 1. Hard fail → 무조건 C
    if compression_ratio > 4.0:
        return "C", "compression_ratio_high"

    if has_repeated_ngram(text, n=3):
        return "C", "repeated_ngram"

    if len(text.strip()) < 2:
        return "C", "too_short"

    # 2. avg_logprob 기준으로 A/B/C 분류
    if avg_logprob > -0.3:
        return "A", "high_confidence"
    elif avg_logprob > -0.7:
        return "B", "medium_confidence"
    else:
        return "C", "low_confidence"
```

### 6.4 임계값 (초기 설정)

| 조건 | 임계값 | 결과 | 비고 |
|------|--------|------|------|
| `compression_ratio` | > 4.0 | → C | 모델 붕괴 |
| 반복 n-gram | 3회 이상 | → C | 텍스트 붕괴 |
| `len(text)` | < 2 | → C | 빈 출력 |
| `avg_logprob` | > -0.3 | → A | 높은 신뢰도 |
| `avg_logprob` | -0.3 ~ -0.7 | → B | 중간 신뢰도 |
| `avg_logprob` | < -0.7 | → C | 낮은 신뢰도 |

> **참고**: 임계값은 실제 데이터의 분포를 확인한 후 조정할 예정

### 6.5 출력 형식

트리아지 결과는 다음 정보를 포함하여 저장:

```python
{
    "sample_id": "train_00001",
    "text_raw": "안녕하세요",
    "bucket": "A",
    "reason": "high_confidence",
    "metrics": {
        "avg_logprob": -0.15,
        "compression_ratio": 1.4,
        "text_length": 5
    }
}
```

---

## 7. 다음 단계 (3.4로의 연결)

3.4 "라벨링 자동화 워크플로우 구현"에서는 다음을 구현한다:

1. **ASR 파이프라인**: Whisper 모델 래퍼, 배치 처리
2. **트리아지 시스템**: 신뢰도 점수 계산, 버킷팅 로직
3. **검수 인터페이스**: 수정 로그 기록
4. **정규화 연동**: Kornormalizer 통합

---

*작성일: 2026-01-13*
