# 3.4 라벨링 자동화 워크플로우 구현

## 1. 개요

3.3에서 설계한 라벨링 자동화 워크플로우를 실제 코드로 구현한다.

**구현 범위:**
- ASR 모듈 (Whisper Large-v3 래퍼)
- 트리아지 모듈 (A/B/C 버킷 분류)
- 파이프라인 통합 (ASR → 트리아지 → 정규화)
- 데이터 로더 개선 (HuggingFace 캐시 지원)

---

## 2. 모듈 구조

```
src/taps/
├── __init__.py              # LabelingPipeline export
├── pipeline.py              # 통합 파이프라인
├── asr/
│   ├── __init__.py          # Transcriber export
│   └── transcriber.py       # Whisper ASR 래퍼
├── triage/
│   ├── __init__.py          # TriageScorer, TriageResult export
│   └── scorer.py            # 트리아지 스코어러
└── data/
    ├── __init__.py          # 데이터 로더 함수 export
    └── loader.py            # 데이터셋 다운로드/로드
```

---

## 3. ASR 모듈 (`src/taps/asr/`)

### 3.1 TranscriptionResult

ASR 결과를 담는 데이터 클래스:

```python
@dataclass
class TranscriptionResult:
    text: str                    # 인식된 텍스트
    avg_logprob: float           # 평균 로그 확률 (신뢰도)
    compression_ratio: float     # 압축 비율 (반복 탐지)
    language: str                # 감지된 언어
    duration: float              # 오디오 길이 (초)
```

### 3.2 Transcriber

Whisper 모델 래퍼:

```python
class Transcriber:
    DEFAULT_MODEL = "large-v3"
    DEFAULT_BEAM_SIZE = 5
    DEFAULT_LANGUAGE = "ko"

    def __init__(self, model_size, device="auto", compute_type="auto"):
        # faster-whisper 모델 로드

    def transcribe(self, audio) -> TranscriptionResult:
        # 단일 오디오 변환

    def transcribe_batch(self, audio_list) -> list:
        # 배치 처리 (tqdm 진행률 표시)
```

**설정값:**
- 모델: `Systran/faster-whisper-large-v3`
- beam_size: 5
- language: "ko"
- temperature: [0.0, 0.2, 0.4]
- vad_filter: True

---

## 4. 트리아지 모듈 (`src/taps/triage/`)

### 4.1 TriageResult

트리아지 결과를 담는 데이터 클래스:

```python
@dataclass
class TriageResult:
    bucket: Literal["A", "B", "C"]  # 분류 결과
    reason: str                     # 분류 사유
    avg_logprob: float
    compression_ratio: float
    text_length: int
    has_repetition: bool
```

### 4.2 TriageThresholds

임계값 설정:

```python
@dataclass
class TriageThresholds:
    # Hard fail 조건
    compression_ratio_max: float = 4.0
    min_text_length: int = 2
    max_ngram_repeat: int = 3

    # avg_logprob 기준
    logprob_high: float = -0.3    # 이상 → A
    logprob_medium: float = -0.7  # 이상 → B, 미만 → C
```

### 4.3 TriageScorer

분류 로직:

```python
class TriageScorer:
    def score(self, text, avg_logprob, compression_ratio) -> TriageResult:
        # 1. Hard fail 체크
        if compression_ratio > 4.0: return "C"
        if has_repeated_ngram(text): return "C"
        if len(text) < 2: return "C"

        # 2. avg_logprob 기준 분류
        if avg_logprob > -0.3: return "A"
        elif avg_logprob > -0.7: return "B"
        else: return "C"
```

---

## 5. 파이프라인 (`src/taps/pipeline.py`)

### 5.1 PipelineResult

파이프라인 결과:

```python
@dataclass
class PipelineResult:
    sample_id: str
    text_raw: str               # ASR 원본 출력
    bucket: str                 # 트리아지 결과
    reason: str                 # 분류 사유
    metrics: dict               # Whisper 메트릭
    text_verified: str = None   # 검수 완료 텍스트
    text_normalized: str = None # 정규화 결과
```

### 5.2 LabelingPipeline

통합 파이프라인:

```python
class LabelingPipeline:
    def __init__(self, model_size="large-v3", device="auto"):
        # 지연 로딩: 실제 사용 시 모델 로드

    def run_asr(self, samples) -> List[PipelineResult]:
        # Step 1+2: ASR + 트리아지

    def normalize_results(self, results) -> List[PipelineResult]:
        # Step 4: 정규화 (외부 Kornormalizer 사용)

    def save_results(self, results, filename) -> Path:
        # JSON으로 결과 저장

    def get_bucket_statistics(self, results) -> dict:
        # 버킷별 통계
```

---

## 6. 데이터 로더 개선

### 6.1 HuggingFace 캐시 지원

`load_from_hf_cache()` 함수 추가:

```python
def load_from_hf_cache(hf_cache_dir="D:/hf_cache") -> DatasetDict:
    """
    HuggingFace 캐시에서 직접 로드
    save_to_disk() 메모리 문제 우회
    """
    return load_dataset(DATASET_NAME, cache_dir=f"{hf_cache_dir}/datasets")
```

### 6.2 오디오 디코딩 처리

datasets 라이브러리의 torchcodec 의존성 문제 해결:

```python
# 오디오 디코딩 비활성화
train = train.cast_column('audio.acoustic_microphone', Audio(decode=False))

# soundfile로 직접 디코딩
audio_bytes = sample['audio.acoustic_microphone']['bytes']
audio_array, sr = sf.read(io.BytesIO(audio_bytes))
audio_array = audio_array.astype(np.float32)  # float32 필수
```

---

## 7. 정규화 연동

외부 Kornormalizer 패키지 사용:

```python
def normalize_results(self, results, numbers=True, alphabet=True, ...):
    # 정규화 패키지 경로 결정
    # 1순위: 환경변수 KORNORMALIZER_PATH
    # 2순위: 프로젝트 상위 폴더의 '정규화' 디렉토리 (../정규화)
    normalizer_path = os.environ.get('KORNORMALIZER_PATH')
    if not normalizer_path:
        project_root = Path(__file__).parent.parent.parent
        normalizer_path = str(project_root.parent / "정규화")

    sys.path.insert(0, normalizer_path)
    from normalizer import normalize

    for result in results:
        source_text = result.text_verified or result.text_raw
        result.text_normalized = normalize(source_text, ...)
```

**경로 설정 방법:**
- 환경변수: `export KORNORMALIZER_PATH=/path/to/kornormalizer`
- 또는 프로젝트와 같은 레벨에 `정규화` 폴더 배치

---

## 8. 테스트 결과

### 8.1 단위 테스트

```bash
cd src && python -m taps.pipeline
# 파이프라인 모듈 테스트
# 정규화: "2024년에 KDH가" → "이천 이십 사 년에 케이 디 에이치 가"
```

### 8.2 통합 테스트

3개 샘플로 전체 파이프라인 테스트:

| 샘플 | sentence_id | bucket | avg_logprob | 결과 |
|------|-------------|--------|-------------|------|
| 0 | u00 | A | -0.077 | high_confidence |
| 1 | u01 | A | -0.054 | high_confidence |
| 2 | u02 | A | -0.049 | high_confidence |

**관찰:**
- TAPS 데이터셋이 깨끗한 실험실 녹음이라 ASR 품질이 높음
- 모든 샘플이 bucket A (자동 확정 후보)
- avg_logprob이 -0.1보다 높음 (매우 높은 신뢰도)

---

## 9. 사용법

### 기본 사용

```python
from taps import LabelingPipeline
from taps.data import load_from_hf_cache
from datasets import Audio
import io
import soundfile as sf
import numpy as np

# 데이터셋 로드
ds = load_from_hf_cache()
train = ds['train'].cast_column('audio.acoustic_microphone', Audio(decode=False))

# 오디오 디코딩
sample = train[0]
audio_bytes = sample['audio.acoustic_microphone']['bytes']
audio_array, sr = sf.read(io.BytesIO(audio_bytes))
audio_array = audio_array.astype(np.float32)

# 파이프라인 실행
pipeline = LabelingPipeline()
result = pipeline.transcriber.transcribe(audio_array)
triage = pipeline.scorer.score(result.text, result.avg_logprob, result.compression_ratio)

print(f"텍스트: {result.text}")
print(f"버킷: {triage.bucket} ({triage.reason})")
```

---

## 10. 의존성

```
faster-whisper>=1.0.0
soundfile
numpy
datasets
tqdm
```

---

## 11. 다음 단계 (3.5로의 연결)

3.5 "검증 시스템 구현 및 검증"에서는 다음을 구현:

1. **전체 데이터셋 처리**: Train/Dev/Test 전체 파이프라인 실행
2. **버킷 분포 분석**: A/B/C 비율 확인, 임계값 조정
3. **검증 시스템**: 정규화 결과 검증, 엣지케이스 탐지
4. **성능 평가**: CER 측정, 정규화 전후 비교

---

*작성일: 2026-01-13*
